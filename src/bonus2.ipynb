{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import pustaka yang diperlukan\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from keras.datasets import mnist\n",
    "# from keras.utils import to_categorical\n",
    "\n",
    "# # Memuat dataset MNIST\n",
    "# (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# # Langkah Preprocessing\n",
    "# ## Mengubah bentuk data dan normalisasi\n",
    "# X_train = X_train.reshape(-1, 1, 28, 28).astype('float32') / 255\n",
    "# X_test = X_test.reshape(-1, 1, 28, 28).astype('float32') / 255\n",
    "\n",
    "# ## Mengubah label menjadi one-hot encoding\n",
    "# y_train = to_categorical(y_train, 10)\n",
    "# y_test = to_categorical(y_test, 10)\n",
    "\n",
    "# print(f\"Bentuk data latih: {X_train.shape}, Bentuk label latih: {y_train.shape}\")\n",
    "# print(f\"Bentuk data uji: {X_test.shape}, Bentuk label uji: {y_test.shape}\")\n",
    "\n",
    "# # Definisikan kelas Conv2D, MaxPool2D, dan ANN_Scratch (gunakan kode dari respon sebelumnya)\n",
    "\n",
    "# class Conv2D:\n",
    "#     def __init__(self, input_channels, num_filters, kernel_size, stride=(1, 1), use_padding=True, activation='relu'):\n",
    "#         self.input_channels = input_channels\n",
    "#         self.num_filters = num_filters\n",
    "#         self.kernel_size = kernel_size\n",
    "#         self.stride = stride\n",
    "#         self.use_padding = use_padding\n",
    "#         self.activation = activation\n",
    "        \n",
    "#         # Inisialisasi filter dan bias\n",
    "#         self.filters = np.random.randn(num_filters, input_channels, kernel_size, kernel_size) * 0.01\n",
    "#         self.biases = np.zeros((num_filters, 1))\n",
    "#         print(f\"Conv2D diinisialisasi: num_filters={num_filters}, kernel_size={kernel_size}, stride={stride}, use_padding={use_padding}, activation={activation}\")\n",
    "\n",
    "#     def forward(self, input):\n",
    "#         self.input = input\n",
    "#         if self.use_padding:\n",
    "#             pad_height = (self.kernel_size - 1) // 2\n",
    "#             pad_width = (self.kernel_size - 1) // 2\n",
    "#             input_padded = np.pad(input, ((0, 0), (0, 0), (pad_height, pad_height), (pad_width, pad_width)), mode='constant')\n",
    "#         else:\n",
    "#             input_padded = input\n",
    "\n",
    "#         batch_size, input_channels, input_height, input_width = input_padded.shape\n",
    "#         output_height = (input_height - self.kernel_size) // self.stride[0] + 1\n",
    "#         output_width = (input_width - self.kernel_size) // self.stride[1] + 1\n",
    "\n",
    "#         self.output = np.zeros((batch_size, self.num_filters, output_height, output_width))\n",
    "\n",
    "#         for b in range(batch_size):\n",
    "#             for f in range(self.num_filters):\n",
    "#                 for i in range(0, output_height):\n",
    "#                     for j in range(0, output_width):\n",
    "#                         vert_start = i * self.stride[0]\n",
    "#                         vert_end = vert_start + self.kernel_size\n",
    "#                         horiz_start = j * self.stride[1]\n",
    "#                         horiz_end = horiz_start + self.kernel_size\n",
    "\n",
    "#                         input_slice = input_padded[b, :, vert_start:vert_end, horiz_start:horiz_end]\n",
    "#                         self.output[b, f, i, j] = np.sum(input_slice * self.filters[f]) + self.biases[f]\n",
    "        \n",
    "#         self.output = self.apply_activation(self.output)\n",
    "#         print(f\"Conv2D forward pass: input shape={input.shape}, output shape={self.output.shape}\")\n",
    "#         return self.output\n",
    "\n",
    "#     def apply_activation(self, x):\n",
    "#         if self.activation == 'relu':\n",
    "#             return np.maximum(0, x)\n",
    "#         elif self.activation == 'sigmoid':\n",
    "#             return 1 / (1 + np.exp(-x))\n",
    "#         elif self.activation == 'linear':\n",
    "#             return x  \n",
    "#         elif self.activation == 'softmax':\n",
    "#             exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "#             return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "#         else:\n",
    "#             raise ValueError(f\"Unsupported activation function: {self.activation}\")\n",
    "\n",
    "\n",
    "# class MaxPool2D:\n",
    "#     def __init__(self, pool_size=(2, 2), stride=(2, 2)):\n",
    "#         self.pool_size = pool_size\n",
    "#         self.stride = stride\n",
    "#         print(f\"MaxPool2D diinisialisasi: pool_size={pool_size}, stride={stride}\")\n",
    "\n",
    "#     def forward(self, input):\n",
    "#         self.input = input\n",
    "#         batch_size, input_channels, input_height, input_width = input.shape\n",
    "#         output_height = (input_height - self.pool_size[0]) // self.stride[0] + 1\n",
    "#         output_width = (input_width - self.pool_size[1]) // self.stride[1] + 1\n",
    "\n",
    "#         self.output = np.zeros((batch_size, input_channels, output_height, output_width))\n",
    "\n",
    "#         for b in range(batch_size):\n",
    "#             for c in range(input_channels):\n",
    "#                 for i in range(0, output_height):\n",
    "#                     for j in range(0, output_width):\n",
    "#                         vert_start = i * self.stride[0]\n",
    "#                         vert_end = vert_start + self.pool_size[0]\n",
    "#                         horiz_start = j * self.stride[1]\n",
    "#                         horiz_end = horiz_start + self.pool_size[1]\n",
    "\n",
    "#                         input_slice = input[b, c, vert_start:vert_end, horiz_start:horiz_end]\n",
    "#                         self.output[b, c, i, j] = np.max(input_slice)\n",
    "\n",
    "#         print(f\"MaxPool2D forward pass: input shape={input.shape}, output shape={self.output.shape}\")\n",
    "#         return self.output\n",
    "\n",
    "\n",
    "# class ANN_Scratch:\n",
    "#     def __init__(self, layers, loss='mse', regularization=None, reg_lambda=0.01, learning_rate=0.01, epochs=1000, batch_size=32):\n",
    "#         self.layers = layers\n",
    "#         self.loss = loss\n",
    "#         self.regularization = regularization\n",
    "#         self.reg_lambda = reg_lambda\n",
    "#         self.learning_rate = learning_rate\n",
    "#         self.epochs = epochs\n",
    "#         self.batch_size = batch_size\n",
    "#         print(f\"ANN diinisialisasi dengan {len(self.layers)} layers\")\n",
    "\n",
    "#     def forward(self, X):\n",
    "#         for layer in self.layers:\n",
    "#             X = layer.forward(X)\n",
    "#         return X\n",
    "\n",
    "#     def backward(self, X, y):\n",
    "#         output = self.forward(X)\n",
    "#         gradient = self.loss_derivative(y, output)\n",
    "        \n",
    "#         for layer in reversed(self.layers):\n",
    "#             gradient = layer.backward(gradient, self.learning_rate)\n",
    "\n",
    "#     def fit(self, X, y):\n",
    "#         for epoch in range(self.epochs):\n",
    "#             for i in range(0, len(X), self.batch_size):\n",
    "#                 X_batch = X[i:i+self.batch_size]\n",
    "#                 y_batch = y[i:i+self.batch_size]\n",
    "#                 self.backward(X_batch, y_batch)\n",
    "            \n",
    "#             if epoch % 10 == 0:\n",
    "#                 loss = self.calculate_loss(X, y)\n",
    "#                 print(f\"Epoch {epoch}, Loss: {loss}\")\n",
    "\n",
    "#     def predict(self, X):\n",
    "#         return self.forward(X)\n",
    "\n",
    "#     def calculate_loss(self, X, y):\n",
    "#         output = self.forward(X)\n",
    "#         if self.loss == 'mse':\n",
    "#             loss = np.mean((y - output) ** 2)\n",
    "#         elif self.loss == 'binary_crossentropy':\n",
    "#             output = np.clip(output, 1e-15, 1 - 1e-15)\n",
    "#             loss = -np.mean(y * np.log(output) + (1 - y) * np.log(1 - output))\n",
    "#         else:\n",
    "#             raise ValueError(f\"Unsupported loss function: {self.loss}\")\n",
    "        \n",
    "#         if self.regularization == 'l1':\n",
    "#             l1_loss = self.reg_lambda * sum(np.sum(np.abs(layer.weights)) for layer in self.layers if hasattr(layer, 'weights'))\n",
    "#             loss += l1_loss\n",
    "#         elif self.regularization == 'l2':\n",
    "#             l2_loss = self.reg_lambda * sum(np.sum(layer.weights ** 2) for layer in self.layers if hasattr(layer, 'weights'))\n",
    "#             loss += l2_loss\n",
    "        \n",
    "#         return loss\n",
    "\n",
    "#     def loss_derivative(self, y, output):\n",
    "#         if self.loss == 'mse':\n",
    "#             return 2 * (output - y) / y.size\n",
    "#         elif self.loss == 'binary_crossentropy':\n",
    "#             output = np.clip(output, 1e-15, 1 - 1e-15)\n",
    "#             return (output - y) / (output * (1 - output))\n",
    "#         else:\n",
    "#             raise ValueError(f\"Unsupported loss function: {self.loss}\")\n",
    "\n",
    "# # Definisikan arsitektur CNN\n",
    "# model = ANN_Scratch([\n",
    "#     Conv2D(input_channels=1, num_filters=6, kernel_size=5, stride=(1, 1), use_padding=True, activation='relu'),\n",
    "#     MaxPool2D(pool_size=(2, 2), stride=(2, 2)),\n",
    "#     Conv2D(input_channels=6, num_filters=16, kernel_size=5, stride=(1, 1), use_padding=False, activation='relu'),\n",
    "#     MaxPool2D(pool_size=(2, 2), stride=(2, 2)),\n",
    "#     Layer(input_size=16 * 4 * 4, output_size=120, activation='relu'),\n",
    "#     Layer(input_size=120, output_size=84, activation='relu'),\n",
    "#     Layer(input_size=84, output_size=10, activation='softmax')\n",
    "# ])\n",
    "\n",
    "# # Latih model dengan dataset MNIST\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# # Evaluasi model\n",
    "# predictions = model.predict(X_test)\n",
    "# accuracy = np.mean(np.argmax(predictions, axis=1) == np.argmax(y_test, axis=1))\n",
    "# print(f\"Test Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /mnt/c/ITB/Pendaftaran_Lab/seleksi_lab_gaib/clone 2/Seleksi-Asisten-Lab-GaIB-22/.venv/lib/python3.10/site-packages (3.5.0)\n",
      "Requirement already satisfied: absl-py in /mnt/c/ITB/Pendaftaran_Lab/seleksi_lab_gaib/clone 2/Seleksi-Asisten-Lab-GaIB-22/.venv/lib/python3.10/site-packages (from keras) (2.1.0)\n",
      "Requirement already satisfied: numpy in /mnt/c/ITB/Pendaftaran_Lab/seleksi_lab_gaib/clone 2/Seleksi-Asisten-Lab-GaIB-22/.venv/lib/python3.10/site-packages (from keras) (1.26.4)\n",
      "Requirement already satisfied: rich in /mnt/c/ITB/Pendaftaran_Lab/seleksi_lab_gaib/clone 2/Seleksi-Asisten-Lab-GaIB-22/.venv/lib/python3.10/site-packages (from keras) (13.7.1)\n",
      "Requirement already satisfied: namex in /mnt/c/ITB/Pendaftaran_Lab/seleksi_lab_gaib/clone 2/Seleksi-Asisten-Lab-GaIB-22/.venv/lib/python3.10/site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: h5py in /mnt/c/ITB/Pendaftaran_Lab/seleksi_lab_gaib/clone 2/Seleksi-Asisten-Lab-GaIB-22/.venv/lib/python3.10/site-packages (from keras) (3.11.0)\n",
      "Requirement already satisfied: optree in /mnt/c/ITB/Pendaftaran_Lab/seleksi_lab_gaib/clone 2/Seleksi-Asisten-Lab-GaIB-22/.venv/lib/python3.10/site-packages (from keras) (0.12.1)\n",
      "Requirement already satisfied: ml-dtypes in /mnt/c/ITB/Pendaftaran_Lab/seleksi_lab_gaib/clone 2/Seleksi-Asisten-Lab-GaIB-22/.venv/lib/python3.10/site-packages (from keras) (0.4.0)\n",
      "Requirement already satisfied: packaging in /mnt/c/ITB/Pendaftaran_Lab/seleksi_lab_gaib/clone 2/Seleksi-Asisten-Lab-GaIB-22/.venv/lib/python3.10/site-packages (from keras) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /mnt/c/ITB/Pendaftaran_Lab/seleksi_lab_gaib/clone 2/Seleksi-Asisten-Lab-GaIB-22/.venv/lib/python3.10/site-packages (from optree->keras) (4.12.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /mnt/c/ITB/Pendaftaran_Lab/seleksi_lab_gaib/clone 2/Seleksi-Asisten-Lab-GaIB-22/.venv/lib/python3.10/site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /mnt/c/ITB/Pendaftaran_Lab/seleksi_lab_gaib/clone 2/Seleksi-Asisten-Lab-GaIB-22/.venv/lib/python3.10/site-packages (from rich->keras) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /mnt/c/ITB/Pendaftaran_Lab/seleksi_lab_gaib/clone 2/Seleksi-Asisten-Lab-GaIB-22/.venv/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-28 17:10:03.312434: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-28 17:10:03.552133: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-28 17:10:03.580353: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-28 17:10:03.615072: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-28 17:10:03.688651: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-28 17:10:03.732257: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-28 17:10:03.941853: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-28 17:10:47.436240: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "import importlib.util\n",
    "import sys\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxsAAACvCAYAAACVbcM3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAbyUlEQVR4nO3de1SVVf7H8e9REfCCjIpalqh5y8lbXocxL4lZXgqTNMtbOebKG8uljqNjysykecMUb7l0eSFdi1wqajZNNiNWloOS6SwyjLxEGMtAA8Qbw/D8/pifTs/ZWzkezuZwDu/XWv6xP+7znK+0A7487Gc7LMuyBAAAAAA8rIq3CwAAAADgn2g2AAAAABhBswEAAADACJoNAAAAAEbQbAAAAAAwgmYDAAAAgBE0GwAAAACMoNkAAAAAYATNBgAAAAAjKn2zceHCBXE4HLJ8+XKPXfPw4cPicDjk8OHDHrsm/BPrD97E+oO3sQbhTay/8uGTzcbWrVvF4XBIamqqt0sxIjY2VhwOh/InKCjI26VB/H/9iYhcvHhRhg8fLqGhoRISEiLPPfecnDt3zttlQSrH+vul/v37i8PhkClTpni7FPw/f1+DZ86ckenTp0tERIQEBQWJw+GQCxcueLss/D9/X38iIomJifL4449LUFCQhIWFyfjx4yU3N9fbZbmtmrcLwN2tX79eatWqdWdctWpVL1aDyqKwsFD69u0r+fn5MnfuXAkICJC3335bevfuLSdPnpR69ep5u0RUEnv27JGjR496uwxUMkePHpX4+Hhp27atPProo3Ly5Elvl4RKZP369TJp0iTp16+frFixQrKysmTVqlWSmpoqKSkpPvmDZ5qNCiw6Olrq16/v7TJQyaxbt04yMjLk2LFj0rVrVxEReeaZZ+Sxxx6TuLg4WbRokZcrRGVw8+ZNmTFjhsyePVvmz5/v7XJQiTz77LOSl5cntWvXluXLl9NsoNwUFRXJ3LlzpVevXvLxxx+Lw+EQEZGIiAgZMmSIbNy4UaZOnerlKu+fT/4alSuKiopk/vz50rlzZ6lTp47UrFlTnnjiCUlOTr7ra95++20JDw+X4OBg6d27t6SlpSlz0tPTJTo6WurWrStBQUHSpUsX2b9/f6n1XL9+XdLT0+/rNphlWVJQUCCWZbn8GlQMvrz+du3aJV27dr3TaIiItGnTRvr16yc7d+4s9fXwPl9ef7ctXbpUSkpKZObMmS6/BhWHL6/BunXrSu3atUudh4rLV9dfWlqa5OXlyYgRI+40GiIigwcPllq1akliYmKp71UR+W2zUVBQIJs2bZI+ffrIkiVLJDY2VnJycmTAgAHan1IkJCRIfHy8TJ48WebMmSNpaWny5JNPyqVLl+7M+frrr6VHjx7yzTffyB/+8AeJi4uTmjVrSlRUlCQlJd2znmPHjsmjjz4qa9ascfnf0Lx5c6lTp47Url1bRo0aZasFFZuvrr+SkhL517/+JV26dFH+rlu3bnL27Fm5evWqax8EeI2vrr/bMjMzZfHixbJkyRIJDg6+r387KgZfX4Pwbb66/m7duiUiov28FxwcLF999ZWUlJS48BGoYCwftGXLFktErOPHj991TnFxsXXr1i1b9vPPP1sNGza0Xn311TvZ+fPnLRGxgoODraysrDt5SkqKJSLW9OnT72T9+vWz2rVrZ928efNOVlJSYkVERFgtW7a8kyUnJ1siYiUnJyvZggULSv33rVy50poyZYq1Y8cOa9euXVZMTIxVrVo1q2XLllZ+fn6pr4dZ/rz+cnJyLBGx/vznPyt/t3btWktErPT09HteA2b58/q7LTo62oqIiLgzFhFr8uTJLr0W5lWGNXjbsmXLLBGxzp8/f1+vgzn+vP5ycnIsh8NhjR8/3panp6dbImKJiJWbm3vPa1REfntno2rVqlK9enUR+e9Pa69cuSLFxcXSpUsXOXHihDI/KipKGjdufGfcrVs36d69u/z1r38VEZErV67IoUOHZPjw4XL16lXJzc2V3NxcuXz5sgwYMEAyMjLk4sWLd62nT58+YlmWxMbGllp7TEyMrF69Wl566SUZNmyYrFy5UrZt2yYZGRmybt26+/xIwBt8df3duHFDREQCAwOVv7u9Ke32HFRcvrr+RESSk5Nl9+7dsnLlyvv7R6NC8eU1CN/nq+uvfv36Mnz4cNm2bZvExcXJuXPn5LPPPpMRI0ZIQECAiPjm12C/bTZERLZt2ybt27eXoKAgqVevnoSFhckHH3wg+fn5ytyWLVsqWatWre487u67774Ty7LkjTfekLCwMNufBQsWiIjITz/9ZOzf8tJLL0mjRo3k73//u7H3gGf54vq7fev29q3cX7p586ZtDio2X1x/xcXFMm3aNBk9erRtzxB8ky+uQfgPX11/GzZskIEDB8rMmTPlkUcekV69ekm7du1kyJAhIiK2p5T6Cr99GtX27dtl3LhxEhUVJbNmzZIGDRpI1apV5a233pKzZ8/e9/Vu/47czJkzZcCAAdo5LVq0KFPNpXn44YflypUrRt8DnuGr669u3boSGBgo2dnZyt/dzh588MEyvw/M8tX1l5CQIGfOnJENGzYo5xpcvXpVLly4IA0aNJAaNWqU+b1glq+uQfgHX15/derUkX379klmZqZcuHBBwsPDJTw8XCIiIiQsLExCQ0M98j7lyW+bjV27dknz5s1lz549th39tztQZxkZGUr27bffStOmTUXkv5u1RUQCAgIkMjLS8wWXwrIsuXDhgnTq1Knc3xv3z1fXX5UqVaRdu3baw5JSUlKkefPmPKXFB/jq+svMzJR///vf8tvf/lb5u4SEBElISJCkpCSJiooyVgM8w1fXIPyDP6y/Jk2aSJMmTUREJC8vT7788ksZNmxYuby3p/ntr1HdPgDP+sVjY1NSUu56QNTevXttv2937NgxSUlJkWeeeUZERBo0aCB9+vSRDRs2aH/qm5OTc8967uexe7prrV+/XnJycuTpp58u9fXwPl9ef9HR0XL8+HFbw3HmzBk5dOiQvPDCC6W+Ht7nq+vvxRdflKSkJOWPiMjAgQMlKSlJunfvfs9roGLw1TUI/+Bv62/OnDlSXFws06dPd+v13ubTdzY2b94sf/vb35Q8JiZGBg8eLHv27JGhQ4fKoEGD5Pz58/LOO+9I27ZtpbCwUHlNixYtpGfPnvL666/LrVu3ZOXKlVKvXj35/e9/f2fO2rVrpWfPntKuXTuZMGGCNG/eXC5duiRHjx6VrKwsOXXq1F1rPXbsmPTt21cWLFhQ6gah8PBwGTFihLRr106CgoLkyJEjkpiYKB07dpSJEye6/gGCUf66/iZNmiQbN26UQYMGycyZMyUgIEBWrFghDRs2lBkzZrj+AYJR/rj+2rRpI23atNH+XbNmzbijUcH44xoUEcnPz5fVq1eLiMjnn38uIiJr1qyR0NBQCQ0NlSlTprjy4YFh/rr+Fi9eLGlpadK9e3epVq2a7N27Vw4ePChvvvmm7+5lK/8HYJXd7cee3e3PDz/8YJWUlFiLFi2ywsPDrcDAQKtTp07WgQMHrLFjx1rh4eF3rnX7sWfLli2z4uLirIcfftgKDAy0nnjiCevUqVPKe589e9YaM2aM1ahRIysgIMBq3LixNXjwYGvXrl135pT1sXu/+93vrLZt21q1a9e2AgICrBYtWlizZ8+2CgoKyvJhg4f4+/qzLMv64YcfrOjoaCskJMSqVauWNXjwYCsjI8PdDxk8qDKsP2fCo28rFH9fg7dr0v35Ze3wDn9ffwcOHLC6detm1a5d26pRo4bVo0cPa+fOnWX5kHmdw7I4nhoAAACA5/ntng0AAAAA3kWzAQAAAMAImg0AAAAARtBsAAAAADCCZgMAAACAETQbAAAAAIxw+VC/Xx73DtxWXk9OZv1Bpzyf3M0ahA6fA+FNrD94k6vrjzsbAAAAAIyg2QAAAABgBM0GAAAAACNoNgAAAAAYQbMBAAAAwAiaDQAAAABG0GwAAAAAMIJmAwAAAIARNBsAAAAAjKDZAAAAAGAEzQYAAAAAI2g2AAAAABhBswEAAADACJoNAAAAAEbQbAAAAAAwgmYDAAAAgBE0GwAAAACMoNkAAAAAYEQ1bxcAoOw6d+6sZFOmTLGNx4wZo8xJSEhQstWrVyvZiRMnylAdAACorLizAQAAAMAImg0AAAAARtBsAAAAADCCZgMAAACAEQ7LsiyXJjocpmvxuqpVqypZnTp13L6e8wbdGjVqKHNat26tZJMnT1ay5cuX28YjR45U5ty8eVPJFi9erGR/+tOf1GLd5OLyKbPKsP5c1bFjRyU7dOiQkoWEhLh1/fz8fCWrV6+eW9cyrbzWnwhr0Nv69etnG+/YsUOZ07t3byU7c+aMsZpE+Bzo6+bNm6dkuq+RVarYfzbbp08fZc4nn3zisbpcxfqDN7m6/rizAQAAAMAImg0AAAAARtBsAAAAADCCZgMAAACAET5/gniTJk2UrHr16koWERGhZD179rSNQ0NDlTnDhg1zvzgXZGVlKVl8fLySDR061Da+evWqMufUqVNK5o0Na/Ccbt26Kdnu3buVTPcgA+eNW7o1U1RUpGS6zeA9evSwjXUniuuuBb1evXopme7jnpSUVB7l+ISuXbvaxsePH/dSJfBV48aNU7LZs2crWUlJSanXKs+HUwC+jjsbAAAAAIyg2QAAAABgBM0GAAAAACN8as+Gq4eZleUgPpN0vweqO1CosLBQyZwPsMrOzlbm/Pzzz0pm+kAruM/5kMfHH39cmbN9+3Yle+CBB9x6v4yMDCVbunSpkiUmJirZ559/bhvr1u1bb73lVl2Vke5AsJYtWypZZd2z4XyAmohIs2bNbOPw8HBlDgeP4V50ayYoKMgLlaAi6t69u5KNGjVKyXSHh/76178u9fozZ85Ush9//FHJnPcTi6jfC6SkpJT6fhUJdzYAAAAAGEGzAQAAAMAImg0AAAAARtBsAAAAADDCpzaIZ2ZmKtnly5eVzPQGcd3GnLy8PCXr27evbaw79Ozdd9/1WF3wLRs2bLCNR44cafT9dBvQa9WqpWS6gyCdNzS3b9/eY3VVRmPGjFGyo0ePeqGSikn3EIQJEybYxrqHJ6SnpxurCb4nMjLSNp46dapLr9Oto8GDB9vGly5dcr8wVAgjRoywjVetWqXMqV+/vpLpHkRx+PBhJQsLC7ONly1b5lJduus7X+vFF1906VoVBXc2AAAAABhBswEAAADACJoNAAAAAEbQbAAAAAAwwqc2iF+5ckXJZs2apWTOG7lERL766isli4+PL/U9T548qWT9+/dXsmvXrimZ84mSMTExpb4f/FPnzp2VbNCgQbaxq6cf6zZwv//++0q2fPly21h3Uqnu/wvdSfRPPvmkbcxJzWWjOyEb/7Np06ZS52RkZJRDJfAVulOXt2zZYhu7+vAY3Ube77//3r3CUO6qVVO/te3SpYuSbdy40TauUaOGMufTTz9Vsr/85S9KduTIESULDAy0jXfu3KnMeeqpp5RMJzU11aV5FRVf8QAAAAAYQbMBAAAAwAiaDQAAAABG0GwAAAAAMMKnNojr7N27V8kOHTqkZFevXlWyDh062Mbjx49X5jhvshXRbwbX+frrr23j1157zaXXwbd17NhRyT7++GMlCwkJsY0ty1LmfPjhh0qmO2m8d+/eSjZv3jzbWLfpNicnR8lOnTqlZCUlJbax8+Z2Ef0J5SdOnFCyykZ32nrDhg29UInvcGUjr+7/KVReY8eOVbIHH3yw1NfpTn5OSEjwREnwklGjRimZKw+d0H1OcT5lXESkoKDApTqcX+vqZvCsrCwl27Ztm0uvrai4swEAAADACJoNAAAAAEbQbAAAAAAwgmYDAAAAgBE+v0Fcx9XNO/n5+aXOmTBhgpK99957Sua8gRaVQ6tWrZRMd6q9bsNrbm6ubZydna3M0W0KKywsVLIPPvjApcxTgoODlWzGjBlK9vLLLxurwVcMHDhQyXQfv8pKt1m+WbNmpb7u4sWLJsqBD6hfv76Svfrqq0rm/HU5Ly9PmfPmm296rC6UP91p3nPnzlUy3QNY1q1bZxs7P1RFxPXvJ3X++Mc/uvW6adOmKZnuYS6+hDsbAAAAAIyg2QAAAABgBM0GAAAAACP8cs+Gq2JjY23jzp07K3N0h6VFRkYq2cGDBz1WFyqmwMBAJdMd+qj7HX3doZJjxoyxjVNTU5U5vvS7/U2aNPF2CRVS69atXZrnfAhoZaH7f0i3j+Pbb7+1jXX/T8H/NG3aVMl2797t1rVWr16tZMnJyW5dC+Vv/vz5Sqbbn1FUVKRkH330kZLNnj3bNr5x44ZLdQQFBSmZ7sA+56+JDodDmaPbM7Rv3z6X6vAl3NkAAAAAYATNBgAAAAAjaDYAAAAAGEGzAQAAAMCISr1B/Nq1a7ax7gC/EydOKNnGjRuVTLfJzHnD79q1a5U5uoNmUDF16tRJyXSbwXWee+45Jfvkk0/KXBP8x/Hjx71dQpmEhIQo2dNPP20bjxo1Spmj21ip43x4l+6ANvgf5zUkItK+fXuXXvuPf/zDNl61apVHakL5CA0NtY0nTZqkzNF9D6XbDB4VFeVWDS1atFCyHTt2KJnuAUPOdu3apWRLly51qy5fw50NAAAAAEbQbAAAAAAwgmYDAAAAgBE0GwAAAACMqNQbxJ2dPXtWycaNG6dkW7ZsUbLRo0eXmtWsWVOZk5CQoGTZ2dn3KhNesmLFCiXTnQiq2/jt65vBq1Sx/1yipKTES5X4r7p163rsWh06dFAy3VqNjIy0jR966CFlTvXq1ZXs5ZdfVjLnNSKinsibkpKizLl165aSVaumfmn68ssvlQz+RbeJd/HixS699siRI0o2duxY2zg/P9+tuuAdzp976tev79Lrpk2bpmQNGjRQsldeecU2fvbZZ5U5jz32mJLVqlVLyXQb1Z2z7du3K3OcH1Tkr7izAQAAAMAImg0AAAAARtBsAAAAADCCZgMAAACAEWwQL0VSUpKSZWRkKJlu83C/fv1s40WLFilzwsPDlWzhwoVKdvHixXvWCc8bPHiwbdyxY0dljm5T2P79+02V5DXOG8J1/+6TJ0+WUzW+xXmTtIj+4/fOO+8o2dy5c916T90Jy7oN4sXFxbbx9evXlTmnT59Wss2bNytZamqqkjk/GOHSpUvKnKysLCULDg5WsvT0dCWDb2vatKltvHv3brevde7cOSXTrTf4jqKiIts4JydHmRMWFqZk58+fVzLd51xX/Pjjj0pWUFCgZA888ICS5ebm2sbvv/++WzX4A+5sAAAAADCCZgMAAACAETQbAAAAAIyg2QAAAABgBBvE3ZCWlqZkw4cPV7IhQ4bYxrqTxydOnKhkLVu2VLL+/fvfT4nwAOdNqrqTlH/66Scle++994zV5GmBgYFKFhsbW+rrDh06pGRz5szxREl+Z9KkSUr2/fffK1lERITH3jMzM1PJ9u7dq2TffPONbfzPf/7TYzXovPbaa0qm2+Cp2+wL/zN79mzb2PlBFPfD1ZPG4Tvy8vJsY90J8wcOHFCyunXrKtnZs2eVbN++fbbx1q1blTlXrlxRssTERCXTbRDXzausuLMBAAAAwAiaDQAAAABG0GwAAAAAMII9Gx7i/LuFIiLvvvuubbxp0yZlTrVq6n+CXr16KVmfPn1s48OHD99XfTDj1q1bSpadne2FSkqn258xb948JZs1a5aSOR+8FhcXp8wpLCwsQ3WVy5IlS7xdglc4H3R6N2U53A0Vk+5Q1Keeesqtazn/rr2IyJkzZ9y6FnxHSkqKkun2fHmS7vux3r17K5luvxF7z/6HOxsAAAAAjKDZAAAAAGAEzQYAAAAAI2g2AAAAABjBBnE3tG/fXsmio6OVrGvXrraxbjO4zunTp5Xs008/dbE6lKf9+/d7u4S7ct6Qqdv4PWLECCXTbb4cNmyYx+oCSpOUlOTtEuBhBw8eVLJf/epXpb5Od9DkuHHjPFESUCrnw31F9JvBLctSMg71+x/ubAAAAAAwgmYDAAAAgBE0GwAAAACMoNkAAAAAYAQbxH+hdevWSjZlyhQle/7555WsUaNGbr3nf/7zHyXTnUCt25AEsxwOxz3HIiJRUVFKFhMTY6qku5o+fbqSvfHGG7ZxnTp1lDk7duxQsjFjxniuMAAQkXr16imZK1/X1q1bp2SFhYUeqQkozUcffeTtEvwCdzYAAAAAGEGzAQAAAMAImg0AAAAARtBsAAAAADCi0mwQ123gHjlypG2s2wzetGlTj9WQmpqqZAsXLlSyinwqdWXifCKo7oRQ3bqKj49Xss2bNyvZ5cuXbeMePXooc0aPHq1kHTp0ULKHHnpIyTIzM21j3UY33eZLoDzpHrzQqlUrJdOdJI2KacuWLUpWpYp7P9v84osvyloO4LYBAwZ4uwS/wJ0NAAAAAEbQbAAAAAAwgmYDAAAAgBE+v2ejYcOGSta2bVslW7NmjZK1adPGY3WkpKQo2bJly2zjffv2KXM4rM+3Va1aVckmTZqkZMOGDVOygoIC27hly5Zu16H7vebk5GTbeP78+W5fHzBFtxfK3d/vR/nr2LGjkkVGRiqZ7mtdUVGRbbx27VplzqVLl9wvDiij5s2be7sEv8BndAAAAABG0GwAAAAAMIJmAwAAAIARNBsAAAAAjKjQG8Tr1q1rG2/YsEGZo9uc5skNPbqNt3FxcUqmOzDtxo0bHqsD5e/o0aO28fHjx5U5Xbt2delausP/dA83cOZ88J+ISGJiopLFxMS4VAfgC37zm98o2datW8u/EJQqNDRUyXSf73QuXrxoG8+cOdMTJQEe89lnnymZ7gEWPOzn3rizAQAAAMAImg0AAAAARtBsAAAAADCCZgMAAACAEV7ZIN69e3clmzVrlpJ169bNNm7cuLFH67h+/bptHB8fr8xZtGiRkl27ds2jdaBiysrKso2ff/55Zc7EiROVbN68eW6936pVq5Rs/fr1Svbdd9+5dX2gInI4HN4uAQC00tLSlCwjI0PJdA8meuSRR2zjnJwczxXmY7izAQAAAMAImg0AAAAARtBsAAAAADCCZgMAAACAEV7ZID506FCXMlecPn1ayQ4cOKBkxcXFSuZ8EnheXp5bNaByyM7OVrLY2FiXMgAiH374oZK98MILXqgEnpKenq5kX3zxhZL17NmzPMoBjNM9OGjTpk1KtnDhQtt46tSpyhzd97D+iDsbAAAAAIyg2QAAAABgBM0GAAAAACNoNgAAAAAY4bAsy3JpIqe8QsPF5VNmrD/olNf6E2ENQo/PgfAm1l/5CwkJUbKdO3cqWWRkpG28Z88eZc4rr7yiZNeuXStDdeXL1fXHnQ0AAAAARtBsAAAAADCCZgMAAACAEezZQJnw+6LwJvZswNv4HAhvYv1VDLp9HM6H+r3++uvKnPbt2yuZLx30x54NAAAAAF5FswEAAADACJoNAAAAAEbQbAAAAAAwgg3iKBM2p8Gb2CAOb+NzILyJ9QdvYoM4AAAAAK+i2QAAAABgBM0GAAAAACNoNgAAAAAY4fIGcQAAAAC4H9zZAAAAAGAEzQYAAAAAI2g2AAAAABhBswEAAADACJoNAAAAAEbQbAAAAAAwgmYDAAAAgBE0GwAAAACMoNkAAAAAYMT/Af6T9PifD5VrAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x200 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "def plot_sample_images(X, y, num_samples=5):\n",
    "    plt.figure(figsize=(10, 2))\n",
    "    for i in range(num_samples):\n",
    "        plt.subplot(1, num_samples, i + 1)\n",
    "        plt.imshow(X[i], cmap='gray')\n",
    "        plt.title(f\"Label: {y[i]}\")\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "plot_sample_images(X_train, y_train, num_samples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(-1, 1, 28, 28).astype('float32') / 255\n",
    "X_test = X_test.reshape(-1, 1, 28, 28).astype('float32') / 255\n",
    "\n",
    "y_train = y_train.astype(int)\n",
    "y_test = y_test.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_name = \"ann-scratch\"\n",
    "module_path = os.path.join('supervised-learning', module_name + '.py') \n",
    "\n",
    "spec = importlib.util.spec_from_file_location(module_name, module_path)\n",
    "ann_module = importlib.util.module_from_spec(spec)\n",
    "sys.modules[module_name] = ann_module\n",
    "spec.loader.exec_module(ann_module)\n",
    "\n",
    "Layer = ann_module.Layer\n",
    "Conv2DLayer = ann_module.Conv2DLayer \n",
    "MaxPooling2DLayer = ann_module.MaxPooling2DLayer  \n",
    "ANN_Scratch = ann_module.ANN_Scratch\n",
    "Flatten = ann_module.Flatten\n",
    "\n",
    "def one_hot_encode(y, num_classes):\n",
    "    return np.eye(num_classes)[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANN fit - X shape: (60000, 1, 28, 28), y shape: (60000, 10)\n",
      "Epoch 1/10\n",
      "  Batch 1 - X_batch shape: (32, 1, 28, 28), y_batch shape: (32, 10)\n",
      "ANN backward - Input shape: (32, 1, 28, 28), y shape: (32, 10)\n",
      "ANN forward - Input shape: (32, 1, 28, 28)\n",
      "Conv2D forward - Input shape: (32, 1, 28, 28)\n",
      "Conv2D forward - Output shape: (32, 6, 28, 28)\n",
      "ANN forward - Output shape after layer 0: (32, 6, 28, 28)\n",
      "MaxPooling forward - Input shape: (32, 6, 28, 28)\n",
      "MaxPooling forward - Output shape: (32, 6, 14, 14)\n",
      "ANN forward - Output shape after layer 1: (32, 6, 14, 14)\n",
      "Conv2D forward - Input shape: (32, 6, 14, 14)\n",
      "Conv2D forward - Output shape: (32, 16, 10, 10)\n",
      "ANN forward - Output shape after layer 2: (32, 16, 10, 10)\n",
      "MaxPooling forward - Input shape: (32, 16, 10, 10)\n",
      "MaxPooling forward - Output shape: (32, 16, 5, 5)\n",
      "ANN forward - Output shape after layer 3: (32, 16, 5, 5)\n",
      "Flatten forward - Input shape: (32, 16, 5, 5)\n",
      "Flatten forward - Output shape: (32, 400)\n",
      "ANN forward - Output shape after layer 4: (32, 400)\n",
      "Layer forward - Input shape: (32, 400)\n",
      "Layer forward - Output shape before activation: (32, 120)\n",
      "Layer forward - Output shape after activation: (32, 120)\n",
      "ANN forward - Output shape after layer 5: (32, 120)\n",
      "Layer forward - Input shape: (32, 120)\n",
      "Layer forward - Output shape before activation: (32, 84)\n",
      "Layer forward - Output shape after activation: (32, 84)\n",
      "ANN forward - Output shape after layer 6: (32, 84)\n",
      "Layer forward - Input shape: (32, 84)\n",
      "Layer forward - Output shape before activation: (32, 10)\n",
      "Layer forward - Output shape after activation: (32, 10)\n",
      "ANN forward - Output shape after layer 7: (32, 10)\n",
      "ANN backward - Initial gradient shape: (32, 10)\n",
      "Layer backward - Output gradient shape: (32, 10)\n",
      "Layer backward - Input gradient shape: (32, 84)\n",
      "ANN backward - Gradient shape after layer 0: (32, 84)\n",
      "Layer backward - Output gradient shape: (32, 84)\n",
      "Layer backward - Input gradient shape: (32, 120)\n",
      "ANN backward - Gradient shape after layer 1: (32, 120)\n",
      "Layer backward - Output gradient shape: (32, 120)\n",
      "Layer backward - Input gradient shape: (32, 400)\n",
      "ANN backward - Gradient shape after layer 2: (32, 400)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Flatten.backward() takes 2 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m y_train_onehot \u001b[38;5;241m=\u001b[39m one_hot_encode(y_train, num_classes)\n\u001b[1;32m     14\u001b[0m y_test_onehot \u001b[38;5;241m=\u001b[39m one_hot_encode(y_test, num_classes)\n\u001b[0;32m---> 16\u001b[0m \u001b[43mlenet_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_onehot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m lenet_model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     20\u001b[0m lenet_predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(lenet_model\u001b[38;5;241m.\u001b[39mpredict(X_test), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/mnt/c/ITB/Pendaftaran_Lab/seleksi_lab_gaib/clone 2/Seleksi-Asisten-Lab-GaIB-22/src/supervised-learning/ann-scratch.py:235\u001b[0m, in \u001b[0;36mANN_Scratch.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    233\u001b[0m     y_batch \u001b[38;5;241m=\u001b[39m y[i:i\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size]\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Batch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - X_batch shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_batch\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, y_batch shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_batch\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 235\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    238\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalculate_loss(X, y)\n",
      "File \u001b[0;32m/mnt/c/ITB/Pendaftaran_Lab/seleksi_lab_gaib/clone 2/Seleksi-Asisten-Lab-GaIB-22/src/supervised-learning/ann-scratch.py:224\u001b[0m, in \u001b[0;36mANN_Scratch.backward\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mANN backward - Initial gradient shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgradient\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers))):\n\u001b[0;32m--> 224\u001b[0m     gradient \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mANN backward - Gradient shape after layer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgradient\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Flatten.backward() takes 2 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "lenet_model = ANN_Scratch([\n",
    "    Conv2DLayer(num_filters=6, kernel_size=5, input_shape=(1, 28, 28), stride=(1, 1), use_padding=True, activation='relu'),\n",
    "    MaxPooling2DLayer(pool_size=(2, 2), stride=(2, 2)),\n",
    "    Conv2DLayer(num_filters=16, kernel_size=5, input_shape=(6, 14, 14), stride=(1, 1), use_padding=False, activation='relu'),\n",
    "    MaxPooling2DLayer(pool_size=(2, 2), stride=(2, 2)),\n",
    "    Flatten(),\n",
    "    Layer(input_size=16*5*5, output_size=120, activation='relu'),\n",
    "    Layer(input_size=120, output_size=84, activation='relu'),\n",
    "    Layer(input_size=84, output_size=10, activation='softmax')\n",
    "], loss='categorical_crossentropy', learning_rate=0.01, epochs=10, batch_size=32)\n",
    "\n",
    "num_classes = 10\n",
    "y_train_onehot = one_hot_encode(y_train, num_classes)\n",
    "y_test_onehot = one_hot_encode(y_test, num_classes)\n",
    "\n",
    "lenet_model.fit(X_train, y_train_onehot)\n",
    "\n",
    "lenet_model.fit(X_train, y_train)\n",
    "\n",
    "lenet_predictions = np.argmax(lenet_model.predict(X_test), axis=1)\n",
    "accuracy = np.mean(lenet_predictions == y_test)\n",
    "print(f\"LeNet Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lenet = model_lenet.predict(X_test)\n",
    "accuracy_lenet = np.mean(np.argmax(predictions_lenet, axis=1) == np.argmax(y_test, axis=1))\n",
    "print(f\"Akurasi Pengujian LeNet: {accuracy_lenet:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
